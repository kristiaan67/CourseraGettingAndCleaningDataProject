---
title: "CodeBook"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data Set

This data set was generated out of the [Human Activity Recognition Using Smartphones Data Set](http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) 
containing the recordings of 30 subjects performing activities of daily living (ADL) 
while carrying a waist-mounted smartphone with embedded inertial sensors.

It can be found in the file *average_data.txt* which is generated by 
running the R script *run_analysis.R*. The file contains a table with the values
separated by a blank and can be loaded with the following command:

```{r eval=FALSE}
read.table('average_data.txt', header = TRUE, sep = " ", stringsAsFactors = TRUE)
```

The loaded data frame has 4 columns:

1. **subject**: the id of the person that generated the data
2. **activity**: the activity being performed (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING)
3. **feature**: the name of the variable in the original data set (66 features)
^[The data set features are described the file *features_info.txt*
that is part of the 'Human Activity Recognition Using Smartphones Data Set' and can be 
found in the directory *UCI HAR Dataset* (after the R script was executed). The list of all feature names can be found in the file *features.txt* in the same
directory.]
4. **average**: the calculated average of each feature grouped by subject and activity

## Generation process

The data set is generated by running the R script *run_analysis.R*. 

```{r eval=FALSE}
source('./run_analysis.R', echo=FALSE)
```

The script performs the following steps:

### Data Preparation

#### Download
The original data set is downloaded as a ZIP-file from https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip 
and after the download it is unzipped in the current working directory.

```{r eval=FALSE}
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip",
              destfile = "UCI_HAR_Dataset.zip", method = "curl", quiet = TRUE)
unzip("UCI_HAR_Dataset.zip")
```

The data set files are found in the directory *UCI HAR Dataset*. In this directory there are 
the following files and directories:

* **README.txt**: general info about the data set files and content
* **features_info.txt**: Shows information about the variables used on the feature vector.
* **features.txt**: List of all features.
* **activity_labels.txt**: Links the class labels with their activity name.
* **train/X_train.txt**: Training set.
* **train/y_train.txt**: Training labels.
* **train/subject_train.txt**: Each row identifies the subject who performed the activity for each window sample. Its range is from 1 to 30.
* **test/X_test.txt**: Test set.
* **test/y_test.txt**: Test labels.
* **test/subject_test.txt**: Each row identifies the subject who performed the activity for each window sample. Its range is from 1 to 30.

### Import & Merge

#### Master Data
First master data common to the training and test data, i.e. the activity labels 
(*activity_labels.txt*) and the feature names (*features.txt*) are loaded. They will
be used to provide a more descriptive name to the variables (i.e the column names) and
to the activities specified by their id in the data sets.

```{r eval=FALSE}
# Read the activity labels
activityLabels <- read.table("UCI HAR Dataset/activity_labels.txt", sep = " ", col.names = c("key", "activity"))
# Read the feature names
featureNames <- read.table("UCI HAR Dataset/features.txt", sep = " ", col.names = c("key", "feature"))
```

### Read / Prepare Test and Training Data

The test and training data is found in 3 different files:

1. **subject_test.txt/subject_train.txt**: the ids of the subjects used in the observations
2. **y_test.txt/y_train.txt**: the ids of the activities used in the observations
3. **X_test.txt/X_train.txt**: the observations, a 561-feature vector with the time and frequency domain variables.

As an example the code to import and prepare the test data:

```{r eval=FALSE}
# Read the subjects
testSubjects <- read.table("UCI HAR Dataset/test/subject_test.txt", col.names = c("subject"))
# Read the activity ids
testLabels <- read.table("UCI HAR Dataset/test/y_test.txt", col.names = c("key"))
# and merge them with the activity labels
testLabels <- merge(testLabels, activityLabels, by.x = "key", by.y = "key")
# Read the feature data and set the column names to the master data feature names
testSet <- read.table("UCI HAR Dataset/test/X_test.txt", col.names = featureNames$feature)
# Add the subjects and activities to the feature data set using a column bind
testSet <- as_tibble(cbind(testSubjects, testLabels, testSet))
```

which results in the following data frame:

    # A tibble: 2,947 x 564
    subject   key activity tBodyAcc.mean..… tBodyAcc.mean..… tBodyAcc.mean..… tBodyAcc.std...X tBodyAcc.std...Y tBodyAcc.std...Z tBodyAcc.mad...X
    2     1 WALKING             0.257          -0.0233          -0.0147           -0.938           -0.920           -0.668           -0.953
    2     1 WALKING             0.286          -0.0132          -0.119            -0.975           -0.967           -0.945           -0.987
    2     1 WALKING             0.275          -0.0261          -0.118            -0.994           -0.970           -0.963           -0.994
    2     1 WALKING             0.270          -0.0326          -0.118            -0.995           -0.973           -0.967           -0.995
    2     1 WALKING             0.275          -0.0278          -0.130            -0.994           -0.967           -0.978           -0.994
    # … with 2,937 more rows, and 554 more variables...
    
The training data is processed in the same way but using the files in the 'train' directory.

### Merge / Tidy Data

First the test and training data frames are merged into one data frame by appending the rows
but only keeping the relevant variables columns (i.e. their value being an average 
or standard deviation calculation). The corresponding column names contain '.mean.' 
(mean calculation) or '.std.' (standard deviation calculation). The 'subject' and 'activity' 
columns are obviously also kept. 

```{r eval=FALSE}
# Append the rows of both data frames using a row bind,
dataSet <- rbind(testSet, trainSet)
# then select only the columns that have ".mean." or ".std." in their name (+ "subject" and "activity")
dataSet <- select(dataSet, 
                  grep("subject|activity|\\.mean\\.|\\.std\\.", names(dataSet), value = TRUE))
```

Note that the selection of the columns is done using the regular expression:

```{r eval=FALSE}
grep("subject|activity|\\.mean\\.|\\.std\\.", names(dataSet), value = TRUE)
```

Second the column names are renamed to a more descriptive version:

* 'Acc' is replaced by 'Acceleration'
* 'Mag' is replaced by 'Magnitude'
* '..' are removed
* the prefix 't' replaced by 'Time.'
* the prefix 'f' replaced by 'Freq.' (for frequency)

```{r eval=FALSE}
# rename the columns
dataSet <- rename_with(dataSet, function(name) {
    str_replace_all(
        str_replace_all(
            str_replace_all(
                str_replace_all(
                    str_replace_all(
                        str_replace_all(
                            str_replace_all(name, "Acc", "Acceleration"),
                            "Mag", "Magnitude"), 
                        "\\.{2}", ""), 
                    "tBody", "Time.Body"), 
                "fBody", "Freq.Body"), 
            "tGravity", "Time.Gravity"), 
        "fGravity", "Freq.Gravity")
    }) 
```

The data set now looks like this:

    # A tibble: 10,299 x 68
    subject activity Time.BodyAccele… Time.BodyAccele… Time.BodyAccele… Time.BodyAccele… Time.BodyAccele… Time.BodyAccele… Time.GravityAcc…
    2 WALKING             0.257          -0.0233          -0.0147           -0.938           -0.920           -0.668            0.936
    2 WALKING             0.286          -0.0132          -0.119            -0.975           -0.967           -0.945            0.927
    2 WALKING             0.275          -0.0261          -0.118            -0.994           -0.970           -0.963            0.930
    2 WALKING             0.270          -0.0326          -0.118            -0.995           -0.973           -0.967            0.929
    2 WALKING             0.275          -0.0278          -0.130            -0.994           -0.967           -0.978            0.927
    # … with 10,289 more rows, and 59 more variables:

### Create Averages Data Set

There are 66 variables that should be aggregated by calculating their average 
for each activity and subject. The data set is therefore melted 
(all columns except for 'subject' and 'activity').

```{r eval=FALSE}
avgValuesSet <- as_tibble(melt(as.data.table(dataSet), 
                               id.vars = c("subject", "activity"), 
                               variable.name = "feature"))
```

The result is a data frame with 4 columns 'subject', 'activity', 'feature', 'value' with 'feature' being the name of the feature and 'value' its measurement:

       subject activity feature                      value
       2       WALKING  Time.BodyAcceleration.mean.X 0.257
       2       WALKING  Time.BodyAcceleration.mean.X 0.286
       2       WALKING  Time.BodyAcceleration.mean.X 0.275
       ...

Finally this data set is aggregated by calculating the mean of the measurements 
grouped by 'subject', 'activity' and 'feature':

```{r eval=FALSE}
avgValuesSet <- group_by(subject, activity, feature) %>%
    summarize(average = mean(value))
```

resulting in the following data frame (written to *average_data.txt*):

       subject activity feature                         average
       1       WALKING  Time.BodyAcceleration.mean.X     0.266 
       1       WALKING  Time.BodyAcceleration.mean.Y    -0.0183
       1       WALKING  Time.BodyAcceleration.mean.Z    -0.108 
       1       WALKING  Time.BodyAcceleration.std.X     -0.546 
       ...


